replicaCount: 3

image:
  # see https://github.com/zalando/spilo/releases
  repository: registry.opensource.zalan.do/acid/spilo-14
  pullPolicy: Always
  tag: 2.1-p5

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

postgresMajorVersion: 14

# Credentials used by Patroni
credentials:
  existingSecret: false
  superuser:
    username: postgrestwo
    password:
  admin:
    username: admin
    password:
  standby:
    username: standby
    password:

# Additional users and databases; each user will have full privileges on the same name of the database
# leave the password empty to generate the password automatically
# example
# additionalCredentials:
#   - username: myapp
#     password:
additionalCredentials: []

# set to allow clients to connect without SSL enabled.
allowNoSSL: true

# Distribution Configuration stores
# Please note that only one of the following stores should be enabled.
kubernetes:
  roleLabel: "spilo-role"
  dcs:
    enable: true
  configmaps:
    enable: true

etcd:
  enable: false
  deployChart: false
  # If not deploying etcd chart, fill-in value for etcd service
  # <service>.<namespace>.svc.cluster.local
  host:
  # Leave blank to use vendored etcd chart
  discovery:
zookeeper:
  enable: false
  deployChart: false
  # If not deploying etcd chart, fill-in list of ZooKeeper members in format:
  # 'host1:port1','host2:port2','etc...'
  hosts:
consul:
  enable: false
  deployChart: false
  # Leave blank to use vendored consul chart
  hosts:

# Extra custom environment variables.
# see https://github.com/zalando/spilo/blob/master/ENVIRONMENT.rst#environment-configuration-settings
env: {}

walG:
  # Specifies whether Wal-G should be enabled
  enabled: false
  # Cron schedule for doing base backups
  scheduleCronJob: 00 01 * * *
  # Amount of base backups to retain
  retainBackups: 2
  # Maximum size of the WAL segments accumulated after the base backup to
  # consider WAL-G restore instead of pg_basebackup
  backupThresholdMegabytes: 1024
  # Maximum ratio (in percents) of the accumulated WAL files to the base backup
  # to consider WAL-G restore instead of pg_basebackup
  backupThresholdPercentage: 30

  # see https://github.com/wal-g/wal-g/blob/master/docs/STORAGES.md
  storage: pvc
  pvc:
    size: 500Mi
    storageClass: netapp-file-backup
    mountPath: /home/postgres/backups

rbac:
  # Specifies whether RBAC resources should be created
  create: true

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

persistentVolume:
  enabled: true
  size: 1G
  storageClass: netapp-block-standard
  subPath: ""
  mountPath: /home/postgres/pgdata
  annotations: {}
  accessModes:
    - ReadWriteOnce

resources:
  {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
nodeSelector: {}

# https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: []

# https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinityTemplate: |
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        topologyKey: "kubernetes.io/hostname"
        labelSelector:
          matchLabels: {{ include "patroni.selectorLabels" . | nindent 10 }}

affinity: {}
## Use an alternate scheduler, e.g. "stork".
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
# schedulerName:

networkPolicy:
  enabled: true

podDisruptionBudget:
  enabled: true
  minAvailable: 1
  maxUnavailable:

standby:
  enabled: false
  host:
  port: 5433

transportServerClaim:
  enabled: false
  interval: 10
  timeout: 10
